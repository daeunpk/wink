import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import numpy as np
import time
import os
import json
from datetime import datetime
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.preprocessing import MinMaxScaler
from spotipy.oauth2 import SpotifyOAuth

# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=
# 1. ëª¨ë¸ ë¡œë“œ
# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=
print("ğŸš€ í•™ìŠµ ë°ì´í„° ìƒì„±ì„ ìœ„í•œ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
try:
    model_ko = SentenceTransformer("jhgan/ko-sroberta-multitask") 
    model_en = SentenceTransformer("all-MiniLM-L6-v2")
    
    ko_dim = model_ko.get_sentence_embedding_dimension()
    en_dim = model_en.get_sentence_embedding_dimension()
    MAX_DIM = max(ko_dim, en_dim)
    
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Ko: {ko_dim}D, En: {en_dim}D) -> ìµœì¢… {MAX_DIM}D")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=
# 2. Spotify API ì¸ì¦
# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=

CLIENT_ID = "9f601ae991474c5f9acbbca99f0d9c7c"
CLIENT_SECRET = "302529b448714aaabc311bdb65772a96"
REDIRECT_URI = "https://nonexactingly-transbay-eboni.ngrok-free.dev/callback"

auth_manager = SpotifyOAuth(
    client_id=CLIENT_ID,
    client_secret=CLIENT_SECRET,
    redirect_uri=REDIRECT_URI,
    scope="user-library-read playlist-read-private",
    open_browser=True
)

# Spotipyê°€ localhost:8888ì—ì„œ Flask-like ì„œë²„ë¥¼ ì—´ì–´ì„œ ê¸°ë‹¤ë¦¼
token_info = auth_manager.get_access_token(as_dict=False)
access_token = token_info

sp = spotipy.Spotify(auth=access_token)
print("âœ… Spotify ì¸ì¦ ì„±ê³µ!")

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
results = sp.search(q="happy", type="track", limit=1)
print("ğŸµ ì˜ˆì‹œ ê²€ìƒ‰ ê²°ê³¼:", results["tracks"]["items"][0]["name"])

# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=
# 3. í—¬í¼ í•¨ìˆ˜ ë° ì„¤ì •
# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=

def get_ensemble_embedding(text_str):
    """
    [í•µì‹¬] ì‚¬ìš©ìì˜ 'ì¶”ë¡ (Script 1)' ë°©ì‹ê³¼ 100% ë™ì¼í•œ ì•™ìƒë¸” ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
    (í‚¤ì›Œë“œ í…ìŠ¤íŠ¸ë¥¼ ë‘ ëª¨ë¸ì— ëª¨ë‘ ì…ë ¥ í›„ í‰ê· )
    """
    if not text_str: # ë¹ˆ í…ìŠ¤íŠ¸ ì˜ˆì™¸ ì²˜ë¦¬
        return np.zeros((1, MAX_DIM))
        
    # "í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸"ë¥¼ ë‘ ëª¨ë¸ì— ëª¨ë‘ ì…ë ¥
    emb_ko = model_ko.encode([text_str]) # (1, 768)
    emb_en = model_en.encode([text_str]) # (1, 384)

    # ì°¨ì› ë§ì¶”ê¸° (MiniLMì„ 768ë¡œ íŒ¨ë”©)
    padded_en = np.pad(emb_en, ((0, 0), (0, MAX_DIM - emb_en.shape[1])))
    
    # --- âœ… [ë²„ê·¸ ìˆ˜ì •] ---
    # ko_dim (ìˆ«ì) ëŒ€ì‹  emb_ko (ë²¡í„°)ë¥¼ ë”í•©ë‹ˆë‹¤.
    emb_ensemble = (padded_en + emb_ko) / 2
    return emb_ensemble # (1, 768)

# ìˆ«ì(Number)ë¡œë§Œ êµ¬ì„±ëœ 13D í”¼ì²˜
FEATURE_KEYS = [
    'danceability', 'energy', 'valence', 'acousticness', 'instrumentalness', 
    'liveness', 'speechiness', 'mode', 'loudness', 'tempo', 
    'key', 'time_signature', 'duration_ms',
]
print(f"âœ… {len(FEATURE_KEYS)}ì°¨ì› ë¬´ë“œ ë²¡í„°(Y)ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

# ì •ê·œí™”ê¸°
scaler_loudness = MinMaxScaler(feature_range=(0, 1)); scaler_loudness.fit(np.array([[-60], [0]]))
scaler_tempo = MinMaxScaler(feature_range=(0, 1)); scaler_tempo.fit(np.array([[40], [220]]))
scaler_key = MinMaxScaler(feature_range=(0, 1)); scaler_key.fit(np.array([[0], [11]]))
scaler_time_sig = MinMaxScaler(feature_range=(0, 1)); scaler_time_sig.fit(np.array([[3], [7]]))
scaler_duration = MinMaxScaler(feature_range=(0, 1)); scaler_duration.fit(np.array([[30000], [600000]]))

def process_features(feature_dict):
    f = feature_dict
    vector = []
    try:
        for key in FEATURE_KEYS:
            if key == 'loudness': vector.append(scaler_loudness.transform([[f[key]]])[0, 0])
            elif key == 'tempo': vector.append(scaler_tempo.transform([[f[key]]])[0, 0])
            elif key == 'key': vector.append(scaler_key.transform([[f[key]]])[0, 0])
            elif key == 'time_signature': vector.append(scaler_time_sig.transform([[f[key]]])[0, 0])
            elif key == 'duration_ms': vector.append(scaler_duration.transform([[f[key]]])[0, 0])
            elif key in f: vector.append(f[key])
        
        if len(vector) == len(FEATURE_KEYS):
            return vector
        else:
            return None
    except Exception as e:
        return None

# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=
# 4. ë°ì´í„° ìˆ˜ì§‘ ë©”ì¸ ë¡œì§
# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=

# [ìˆ˜ì •] í•œ/ì˜ í‚¤ì›Œë“œ í˜¼í•© ì‚¬ìš©
SEARCH_KEYWORDS = [
    'happy', 'sad', 'angry', 'chill', 'study', 'workout', 'party', 'focus', 'sleep', 
    'morning', 'driving', 'romance', 'jazz', 'classical', 'K-Pop',
    'í–‰ë³µí•œ', 'ìŠ¬í”ˆ', 'ìš°ìš¸í•œ', 'ì‹ ë‚˜ëŠ”', 'ê³µë¶€', 'ìš´ë™', 'íŒŒí‹°', 'ì§‘ì¤‘', 
    'ìƒˆë²½', 'ë“œë¼ì´ë¸Œ', 'ë¡œë§¨í‹±', 'ì¬ì¦ˆ', 'í´ë˜ì‹', 'ê°ì„±'
]
PLAYLISTS_PER_KEYWORD = 5

training_data_X = []
training_data_Y = []
metadata_list = []

print(f"\nğŸš€ {len(SEARCH_KEYWORDS)}ê°œ í‚¤ì›Œë“œë¡œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê²€ìƒ‰ ë° í”¼ì²˜ ìˆ˜ì§‘ ì‹œì‘...")

for keyword in tqdm(SEARCH_KEYWORDS, desc="ì „ì²´ í‚¤ì›Œë“œ ì§„í–‰ë„"):
    try:
        results = sp.search(q=keyword, type='playlist', limit=PLAYLISTS_PER_KEYWORD)
        playlists = results['playlists']['items']
    except Exception as e:
        print(f"âš ï¸ '{keyword}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ (Rate Limit?): {e}")
        print("   -> 10ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
        time.sleep(10)
        continue

    for pl in tqdm(playlists, desc=f"'{keyword}' í”Œë ˆì´ë¦¬ìŠ¤íŠ¸", leave=False):
        try:
            if not pl:
                continue 

            playlist_id = pl['id']
            playlist_name = pl['name']
            playlist_desc = pl.get('description', '')
            
            x_text_input = playlist_name + " " + playlist_desc
            if not x_text_input.strip(): continue

            # --- 1. X (ì…ë ¥ ë²¡í„°) ìƒì„± ---
            x_input = get_ensemble_embedding(x_text_input) 
            x_input_squeezed = x_input.squeeze()

            # --- 2. Y (ì •ë‹µ ë²¡í„°) ìƒì„± ---
            
            # --- ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] API í˜¸ì¶œ 1 ---
            tracks = sp.playlist_tracks(playlist_id, limit=30)['items']
            
            # --- ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] API í˜¸ì¶œ 1ê³¼ 2 ì‚¬ì´ì— íœ´ì‹ ---
            time.sleep(0.5) 
            
            track_ids_names = []
            for item in tracks:
                if item and item['track'] and item['track']['id']:
                     track_ids_names.append((item['track']['id'], item['track']['name']))

            if not track_ids_names: continue

            track_ids = [t[0] for t in track_ids_names]
            
            # --- ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] API í˜¸ì¶œ 2 ---
            features_list = sp.audio_features(tracks=track_ids)
            features_list = [f for f in features_list if f is not None]

            if not features_list: continue

            # --- 3. ê°œë³„ ê³¡ ë‹¨ìœ„ë¡œ X, Y ì €ì¥ ---
            valid_song_count = 0
            for f in features_list:
                y_vector = process_features(f) 
                if y_vector is not None:
                    training_data_X.append(x_input_squeezed)
                    training_data_Y.append(y_vector)
                    valid_song_count += 1
            
            if valid_song_count > 0:
                metadata_list.append({
                    "keyword": keyword, "playlist_id": playlist_id,
                    "playlist_name": playlist_name, "added_songs": valid_song_count 
                })            
            time.sleep(0.5) 

        except spotipy.exceptions.SpotifyException as se:
            if se.http_status == 429: 
                print("ğŸ”¥ Rate Limit (429)! 30ì´ˆ ëŒ€ê¸°...")
                time.sleep(30)
            elif se.http_status == 403: pass 
            elif se.http_status == 404: pass
            else: 
                print(f"ğŸ”¥ Spotify ì˜¤ë¥˜: {se}")
        except Exception as e:
            print(f"ğŸ”¥ Python ë‚´ë¶€ ì˜¤ë¥˜: {e}") 
            
    # --- ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] ë‹¤ìŒ 'í‚¤ì›Œë“œ' ê²€ìƒ‰ ì „ 'ì¶©ë¶„í•œ' íœ´ì‹ ---
    time.sleep(3.0)
        
# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=
# 5. ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥
# =_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=_=
if not training_data_X:
    print("\nâŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë‚˜ API ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("   (ID/Secretì€ ì •ìƒì´ë‚˜, ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ëª¨ë“  í”Œë¦¬ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
else:
    X_train_data = np.array(training_data_X)
    Y_train_data = np.array(training_data_Y)

    SAVE_DIR = "training_dataset"
    os.makedirs(SAVE_DIR, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    save_path_x = f"{SAVE_DIR}/X_train_{timestamp}.npy"
    save_path_y = f"{SAVE_DIR}/Y_train_{timestamp}.npy"
    meta_path = f"{SAVE_DIR}/meta_{timestamp}.json"

    np.save(save_path_x, X_train_data)
    np.save(save_path_y, Y_train_data)
    
    meta = {
        "timestamp": timestamp,
        "total_samples": len(training_data_X),
        "total_playlists_processed": len(metadata_list),
        "search_keywords": SEARCH_KEYWORDS,
        "feature_keys_used": FEATURE_KEYS,
        "x_shape": X_train_data.shape,
        "y_shape": Y_train_data.shape,
    }
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)

    print(f"\n\nâœ… ì´ {len(training_data_X)}ê°œì˜ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"  (ì´ {len(metadata_list)}ê°œì˜ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œë¨)")
    print(f"  â¡ï¸ X (ì…ë ¥) ì €ì¥: {save_path_x}")
    print(f"  â¡ï¸ Y (ì •ë‹µ) ì €ì¥: {save_path_y}")
    print(f"  â¡ï¸ ë©”íƒ€ ì •ë³´ ì €ì¥: {meta_path}")