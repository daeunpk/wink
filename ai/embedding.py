# active_session.json íŒŒì¼ì˜ ì˜ì–´ í‚¤ì›Œë“œì— ëŒ€í•œ ì„ë² ë”© ì¶”ê°€
# MiniLM-L6-v2 ëª¨ë¸ ì‚¬ìš© (ì˜ì–´ ì „ìš©)

import json
from sentence_transformers import SentenceTransformer
import os
from datetime import datetime

# =========================================================
# 1. ì„¤ì •
# =========================================================
SESSION_JSON_PATH = "agents/keywords/active_session.json"
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2" # ğŸ‘ˆ ì˜ì–´ ì „ìš© ëª¨ë¸ë§Œ ì‚¬ìš©

# =========================================================
# 2. ì„¸ì…˜ íŒŒì¼ ë¡œë“œ
# =========================================================
if not os.path.exists(SESSION_JSON_PATH):
    print(f"âŒ ì„¸ì…˜ íŒŒì¼({SESSION_JSON_PATH})ì´ ì—†ìŠµë‹ˆë‹¤. agent3_keywordExtractor.py ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    exit()

print(f"ğŸ”„ Loading session file: {SESSION_JSON_PATH}")
with open(SESSION_JSON_PATH, "r", encoding="utf-8") as f:
    session_data = json.load(f)

# =========================================================
# 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
# =========================================================
print(f"ğŸš€ Loading embedding model ({EMBEDDING_MODEL_NAME})...")
try:
    model_en = SentenceTransformer(EMBEDDING_MODEL_NAME)
    print("âœ… Model loaded.")
except Exception as e:
    print(f"âŒ Failed to load model: {e}")
    exit()

# =========================================================
# 4. ê° í„´(Turn)ë³„ í‚¤ì›Œë“œ ì„ë² ë”© ìƒì„±
# =========================================================
print("ğŸ’¬ Processing English keywords for embedding...")

# ê¸°ì¡´ ì„ë² ë”©ì´ ìˆìœ¼ë©´ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘
all_embeddings = session_data.get("english_keyword_embeddings", [])
processed_count = 0

# english_keywords ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒ (ê° ìš”ì†Œê°€ í•œ í„´ì˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸)
for i, keywords_list in enumerate(session_data.get("english_keywords", [])):
    
    # [í•µì‹¬] ğŸ‘ˆ ì´ë¯¸ í•´ë‹¹ í„´(i)ì˜ ì„ë² ë”©ì´ ì¡´ì¬í•˜ë©´ ê±´ë„ˆë›°ê¸°
    if i < len(all_embeddings) and all_embeddings[i]:
        continue 
        
    if not keywords_list: # í‚¤ì›Œë“œê°€ ì—†ëŠ” í„´ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        if i >= len(all_embeddings):
             all_embeddings.append([])
        continue

    # 1. í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨ (ì˜ˆ: "cozy winter peaceful")
    keywords_text = " ".join(keywords_list)
    print(f"   -> Turn {i+1}: Embedding '{keywords_text}'")
    
    # 2. ì˜ì–´ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± (NumPy ë°°ì—´)
    embedding_vector_np = model_en.encode([keywords_text])[0]
    
    # 3. JSON ì €ì¥ì„ ìœ„í•´ NumPy ë°°ì—´ì„ Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    embedding_vector_list = embedding_vector_np.tolist()
    
    # 4. ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë˜ëŠ” ê¸°ì¡´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸)
    if i >= len(all_embeddings):
        all_embeddings.append(embedding_vector_list)
    else:
        all_embeddings[i] = embedding_vector_list # (ì´ì „ í„´ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ë®ì–´ì“°ê¸°)
        
    processed_count += 1

# =========================================================
# 5. ì„¸ì…˜ íŒŒì¼ ì—…ë°ì´íŠ¸ (ì„ë² ë”© ì¶”ê°€/ë®ì–´ì“°ê¸°)
# =========================================================
if processed_count > 0:
    session_data["english_keyword_embeddings"] = all_embeddings
    
    print(f"\nğŸ’¾ Updating session file with {processed_count} new embedding(s)...")
    with open(SESSION_JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(session_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… Session file updated: {SESSION_JSON_PATH}")
else:
    print("\nâœ… No new keywords to embed. Session file is up-to-date.")