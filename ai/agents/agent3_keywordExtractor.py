# main pipeline
# -*- coding: utf-8 -*-
"""
Agent3 (í†µí•© íŒŒì´í”„ë¼ì¸)
- Agent 1 ë¡œì§: í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì…ë ¥ â†’ ì˜ì–´ ë²ˆì—­ (EXAONE)
- Agent 2 ë¡œì§: ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥ â†’ ì˜ì–´ ìº¡ì…˜ (Ollama Gemma3)
- Agent 3 ë¡œì§ (1): ë‘ ì˜ì–´ ë¬¸ì¥ â†’ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„± (Ollama Gemma3)
- Agent 3 ë¡œì§ (2): ì¬ì‘ì„±ëœ ë¬¸ì¥ â†’ ì˜ì–´ í‚¤ì›Œë“œ 5ê°œ ì¶”ì¶œ (Ollama Gemma3)
- ì„¸ì…˜ ê´€ë¦¬: ëª¨ë“  ê²°ê³¼ë¥¼ 'active_session.json'ì— ëˆ„ì  ì €ì¥
"""

import os
import re
import json
import base64
from datetime import datetime
import requests
# import torch
# from transformers import AutoModelForCausalLM, AutoTokenizer
# from rag_recommender import recommend_song_based_on_context

# agent1 import
try:
    from agent1_exaone import korean_to_english
except ImportError:
    print("âŒ 'agents/exaone_agent.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# agent2 import
try:
    from agent2_imageToEng import image_to_english_caption
except ImportError:
    print("âŒ 'agents/agent2_imageToEng.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()
    
# rag import
try:
    from context_manager import get_full_conversation_history
except ImportError:
    print("âŒ 'agents/context_manager.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()
    
# =========================================================
# 1. ì „ì—­ ì„¤ì •
# =========================================================
OLLAMA_URL = "http://localhost:11434"
GEMMA3_MODEL = "gemma3:27b" # (Ollamaê°€ ë©€í‹°ëª¨ë‹¬ì„ ì§€ì›í•˜ëŠ” ëª¨ë¸ ID)
SAVE_DIR = "agents/keywords"
os.makedirs(SAVE_DIR, exist_ok=True)

# =========================================================
# 5. [Agent 3-1] ë‘ ì˜ì–´ ë¬¸ì¥ í•©ì¹˜ê¸° (Ollama Gemma3)
# =========================================================
def rewrite_combined_sentence(text1: str, text2: str, full_history: str) -> str:
    """
    (Agent 3, 1ë‹¨ê³„)
    (ìˆ˜ì •) 'ì „ì²´ ëŒ€í™” ì´ë ¥'ê³¼ 'ìƒˆ ì…ë ¥'ì„ Ollamaë¡œ ê²°í•©(ì¬ì‘ì„±)í•©ë‹ˆë‹¤.
    """
    
    # --- 1. ìƒˆ ì…ë ¥ ì¡°í•© ---
    new_input_sentence = f"{text1} {text2}".strip()
    if not new_input_sentence:
        # (ì˜ˆ: "ë¹„ ì˜¤ëŠ” ë‚ " -> "ë” ì°¨ë¶„í•˜ê²Œ")
        # ìƒˆ ì…ë ¥(text1, text2)ì´ ì—†ë”ë¼ë„, ì´ì „ ì´ë ¥(full_history)ë§Œìœ¼ë¡œ
        # Gemma3ê°€ í‚¤ì›Œë“œë¥¼ ë‹¤ì‹œ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ìƒˆ ì…ë ¥ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ë¡œ ê°„ì£¼í•˜ê³  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        print("âš ï¸ [Agent 3] No new input text or image provided.")
        return ""

    print("ğŸ§© [Agent 3] Merging (Context + New Input) sentences (Ollama)...")

    # [í•µì‹¬] ğŸ‘ˆ Gemma3ì—ê²Œ 'ì´ì „ ëŒ€í™”'ì™€ 'ìƒˆ ìš”ì²­'ì„ í•¨ê»˜ ì „ë‹¬
    prompt = f"""
You are a context-aware chat assistant. Your job is to understand the user's full request by combining their past conversation history with their newest input.

[Past Conversation History]
{full_history}

[User's Newest Input]
"{new_input_sentence}"

Combine *all* this context (History + New Input) into ONE single, updated descriptive sentence that reflects the user's *final* intent.
For example, if History is "Rainy day" and New Input is "make it calmer", the output should be "A calm and rainy day".

Respond *only* with the final combined English sentence.
"""
    
    messages = [{"role": "user", "content": prompt.strip()}]
    payload = {"model": GEMMA3_MODEL, "messages": messages, "stream": False, "format": "text"}
    try:
        res = requests.post(f"{OLLAMA_URL}/api/chat", json=payload, timeout=60)
        res.raise_for_status()
        
        raw_response = (res.json().get("message", {}).get("content", "") or "").strip()
        match = re.search(r'["\'](.*?_*)["\']', raw_response)
        if match:
            return match.group(1).strip()
        return raw_response.split('\n')[-1].strip()
        
    except Exception as e:
        print(f"âš ï¸ Merge failed: {e}")
        return new_input_sentence # ì‹¤íŒ¨ ì‹œ ìƒˆ ì…ë ¥ë§Œ ë°˜í™˜
    
# =========================================================
# 6. [Agent 3-2] ê°ì„± í‚¤ì›Œë“œ ì¶”ì¶œ (Gemma3) - (ìˆ˜ì •: JSON ëª¨ë“œ)
# =========================================================
def extract_keywords(merged_text: str, k: int = 3) -> list[str]:
    if not merged_text.strip():
        return []
    print("ğŸ’¬ [Agent 3] Extracting mood keywords (Ollama w/ JSON)...")

    prompt_content = f"""
From the text below, extract exactly {k} keywords that **best describe and are most relevant to** the core mood, atmosphere, or genre.
Text:
"{merged_text}"
"""
    system_prompt = """
You are an expert keyword extractor.
Respond *only* with a valid JSON object in this format:
{"keywords": ["keyword1", "keyword2", "keyword3"]}
"""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt_content}
    ]
    payload = {"model": GEMMA3_MODEL, "messages": messages, "stream": False, "format": "json"}
    try:
        res = requests.post(f"{OLLAMA_URL}/api/chat", json=payload, timeout=60)
        res.raise_for_status()

        # âœ… Ollama ì‘ë‹µ êµ¬ì¡° ëŒ€ì‘
        raw_output = (
            res.json().get("message", {}).get("content")
            or res.json().get("response")
            or ""
        ).strip()

        try:
            parsed_data = json.loads(raw_output)
            keywords = parsed_data.get("keywords", [])
        except json.JSONDecodeError:
            print(f"âš ï¸ JSON parsing failed. Raw: {raw_output}")
            raw = re.sub(r"[^a-zA-Z,\n ]", "", raw_output)
            keywords = [w.strip().lower() for w in re.split(r"[, \n]+", raw) if w.strip()]

        # âœ… í•„í„°ë§ ë° ìƒí•œ ì œí•œ
        keywords = [w for w in keywords if 2 <= len(w) <= 15][:k]
        print(f"ğŸª¶ Extracted keywords â†’ {keywords}")
        return keywords

    except Exception as e:
        print(f"ğŸ”¥ Keyword extraction failed: {e}")
        return []
    
# =========================================================
# 8. ì„¸ì…˜ ì €ì¥
# =========================================================
def save_to_session_simple(data: dict, session_file: str):
    """
    ì§€ì •ëœ ì„¸ì…˜ JSON íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì—´ê³ , ë°ì´í„°ë¥¼ appendí•©ë‹ˆë‹¤.
    íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    default_structure = {
        "session_name": os.path.basename(session_file).replace(".json", ""),
        "session_start": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "input_korean": [], "input_image": [],
        "english_text_from_agent1": [], "english_caption_from_agent2": [],
        "merged_sentence": [], "english_keywords": []
    }
    
    if os.path.exists(session_file):
        try:
            with open(session_file, "r", encoding="utf-8") as f:
                session_data = json.load(f)
            for key, default_value in default_structure.items():
                if key not in session_data:
                    session_data[key] = default_value
        except json.JSONDecodeError:
            print(f"âš ï¸ ì„¸ì…˜ íŒŒì¼ì´ ì†ìƒë˜ì–´ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤: {session_file}")
            session_data = default_structure
    else:
        session_data = default_structure

    try:
        session_data["input_korean"].append(data["input"]["korean_text"])
        session_data["input_image"].append(data["input"]["image_path"])
        session_data["english_text_from_agent1"].append(data["english_text_from_agent1"])
        session_data["english_caption_from_agent2"].append(data["english_caption_from_agent2"])
        session_data["merged_sentence"].append(data["merged_sentence"])
        session_data["english_keywords"].append(data["english_keywords"])
        # session_data["korean_keywords"].append(data["korean_keywords"])
    except KeyError as e:
        print(f"ğŸ”¥ ë°ì´í„° ì €ì¥ ì¤‘ ì¹˜ëª…ì ì¸ Key Error ë°œìƒ: {e}")
        return

    with open(session_file, "w", encoding="utf-8") as f:
        json.dump(session_data, f, ensure_ascii=False, indent=2)

# =========================================================
# 9. ì „ì²´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
# =========================================================
def run_agent_pipeline(korean_text="", image_path="") -> dict:
    """
(ìˆ˜ì •) 'active_session.json'ì—ì„œ 'ì „ì²´ ì´ë ¥'ì„ ë¡œë“œí•œ í›„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    
    # --- [ìˆ˜ì •] 1. RAG: ì „ì²´ ëŒ€í™” ì´ë ¥ ë¡œë“œ ---
    session_file_path = os.path.join(SAVE_DIR, "active_session.json")
    full_history = get_full_conversation_history(session_file_path)
    
    # [Agent 1]
    english_text = korean_to_english(korean_text) if korean_text else ""
    # [Agent 2]
    english_caption = image_to_english_caption(image_path) if image_path else ""
    # [Agent 3-1]
    merged = rewrite_combined_sentence(english_text, english_caption, full_history)    # [Agent 3-2]
    # [Agent 3-2]: ì˜ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ
    eng_keywords = extract_keywords(merged, k=3)
    
    session_file_path = os.path.join(SAVE_DIR, "active_session.json")

    data = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "input": {"korean_text": korean_text, "image_path": image_path},
        "english_text_from_agent1": english_text,
        "english_caption_from_agent2": english_caption,
        "merged_sentence": merged,
        "english_keywords": eng_keywords,
    }

    session_file_path = os.path.join(SAVE_DIR, "active_session.json")
    save_to_session_simple(data, session_file_path)
    
    print(f"\nâœ… Saved to active session â†’ {session_file_path}")
    return data

# =========================================================
# 10. CLI (ì„¸ì…˜ ê´€ë¦¬ì)
# =========================================================
if __name__ == "__main__":
    print("\nğŸ¤– Agent Pipeline (ì„¸ì…˜í˜• ì‹¤í–‰)")
    
    active_session_path = os.path.join(SAVE_DIR, "active_session.json")
    choice = input("\nìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ 'new' ì…ë ¥ (ê¸°ì¡´ ëŒ€í™” ì´ì–´í•˜ê¸°ëŠ” Enter): ").strip().lower()

    if choice == "new":
        if os.path.exists(active_session_path):
            try:
                with open(active_session_path, "r", encoding="utf-8") as f:
                    old_data = json.load(f)
                start_time_str = old_data.get("session_start", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                ts = datetime.strptime(start_time_str, "%Y-%m-%d %H:%M:%S").strftime('%Y%m%d_%H%M%S')
                archive_name = f"session_{ts}.json"
            except Exception as e:
                archive_name = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}_corrupted.json"
            
            archive_path = os.path.join(SAVE_DIR, archive_name)
            os.rename(active_session_path, archive_path)
            print(f"   -> ğŸ—‚ï¸  ê¸°ì¡´ ëŒ€í™”({active_session_path.split('/')[-1]})ë¥¼ '{archive_name}'(ìœ¼)ë¡œ ë³´ê´€í•©ë‹ˆë‹¤.")
            
        print(f"   -> ğŸ†• ìƒˆ ëŒ€í™”({active_session_path.split('/')[-1]})ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        
    else:
        print(f"   -> â¡ï¸  ê¸°ì¡´ ëŒ€í™”({active_session_path.split('/')[-1]})ì— ì´ì–´í•©ë‹ˆë‹¤.")
        if not os.path.exists(active_session_path):
            print("      (ê¸°ì¡´ íŒŒì¼ì´ ì—†ì–´ ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤)")

    print("\n--- ğŸ’¬ ì…ë ¥ì„ ì‹œì‘í•˜ì„¸ìš” ---")
    text = input("í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì…ë ¥ (ì—†ìœ¼ë©´ Enter): ").strip()
    img = input("ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì…ë ¥ (ì—†ìœ¼ë©´ Enter): ").strip()

    if not text and not img:
        print("\nğŸ›‘ ì…ë ¥ì´ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit()

    print("\n--- ğŸš€ ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---")
    try:
        result = run_agent_pipeline(text, img) 
        print("\n--- ğŸ¯ ì‹¤í–‰ ê²°ê³¼ ---")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    except Exception as e:
        print(f"\nğŸ”¥ğŸ”¥ğŸ”¥ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")